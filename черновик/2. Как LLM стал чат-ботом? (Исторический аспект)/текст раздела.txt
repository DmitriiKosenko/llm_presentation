2. Как LLM стал чат-ботом? (Исторический аспект)

--------------------------------------------------------------------------------
Предыдущий раздел называется "Введение"
Следующий раздел "Как человеческий разум взаимодействует с LLM"

--------------------------------------------------------------------------------
В предыдущем разделе мы определили место больших языковых моделей в области знаний ИИ. Это генеративный инструмент для создания информации на человеческом языке.

Давайте посмотрим, откуда вообще появились большие языковые модели, как они развивались и как стали именно такими, какими их знает большинство пользователей, а именно чат-ботами.

Развитие информационных систем, помогающих человеку принимать решения, началось с появления в 1950-х годах экспертных систем, описывающих алгоритм действий по выбору решения в зависимости от конкретных условий.

Первой вехой стал 1957 год, когда Фрэнк Розэнблатт создал перцептрон. Перцептроном он назвал устройство, которое моделировало процесс человеческого восприятия. Это была простая модель искусственной нейронной сети. В 1960 году Розэнблат показал, как она работает, на первом в истории нейрокомпьютере «Марк-1».

Затем, в 1965 году Джозеф Вайценбаум создает Элизу. Элиза была простым чат-ботом. Она анализировала предложения, которые вводил пользователь, и находила ключевые слова. Программа показала, что компьютер может участвовать в осмысленных диалогах на естественном языке. 

В 1970м Марвин Минский и Сеймур Паперт опубликовали книгу «Перцептроны». В ней они показали, что перцептрон не способен решать целый ряд задач, связанных с инвариантным представлением. Например, читать буквы или цифры, которые по-разному расположены на странице. После публикации интерес к исследованию нейросетей упал настолько, что семидесятые стали называть «зимой искусственного интеллекта». Снизился не только научный интерес, но и субсидии американских правительственных организаций.

В 1986 году Дэвид Румельхарт и Джеффри Хинтон предложили метод обратного распространения ошибки. На смену однослойному перцептрону Розэнблатта пришел многослойный. Математический аппарат метода обратного распространения ошибки довольно прост. Но он позволил нейронным сетям обучаться на данных значительно сложнее и разнообразнее, чем раньше.

На смену экспертным системам пришло машинное обучение, благодаря которому информационные системы начали самостоятельно формировать правила и находить решение на основе анализа зависимостей, используя исходные наборы данных (без предварительного составления человеком перечня возможных решений).

Важным событием запонмился 1997 год, когда IBM Deep Blue победила чемпиона мира по шахматам Гарри Каспарова. Эта победа продемонстрировала возможности машинного обучения и анализа больших данных. Событие стало источником вдохновения для дальнейших исследований искусственного интеллекта.

В 2007м IBM представила систему Watson. Архитектура этой системы включала в себя различные методы анализа и обработки естественного языка. Например, компьютер делил текст на отдельные слова и фразы, а затем преобразовывал их в токены. 

В 2015 году Сэм Олтмен, тогда еще глава инкубатора Y Combinator, устроил ужин в отеле Rosewood Sand Hill в сердце Кремниевой долины, Менло-Парке. Участники ужина хотели создать лабораторию, которая будет конкурировать с Google. Так появилась некоммерческая компания, которая заявляла своей миссией демократизацию передовых технологий ИИ. Команда проекта пообещала публиковать все свои разработки и открыть исходный код новых технологий. Эту идею они отразили в названии — OpenAI. 

В 2017м инженеры Google описали архитектуру Transformer, которая стала доминирующая архитектура нейронных сетей для NLP. А в 2018м году OpenAI представила GPT-1.

Позже, в 2020м году OpenAI представила GPT-3. Модель научилась генерировать тексты, как человек. В результате развития GPT-3 появился ChatGPT. Это версия модели, которая обучалась не только на текстах из интернета, но и на диалоговых данных. Если до появления ChatGPT языковые модели все еще по большей части были объектом теоретических исследований, то теперь их стали широко применять на практике.

В процессе работы специалисты OpenAI пришли к выводу, что если предварительно обучать модель на разнообразном корпусе неаннотированного текста, она сможет значительно лучше понимать естественный язык, отвечать на вопросы, оценивать семантическую близость и выполнять другие подобные задачи. Так появился чат-бот для взаимодействия с языковыми моделями внутри компании.

По версии, которую излагает Fortune, идея выкатить на широкую аудиторию чат для более эффективного обучения модели появилась у одной из команд OpenAI. 

ChatGPT вызвал такой интерес отчасти благодаря сравнительной простоте и доступности — бесплатная бета-версия сейчас доступна для всех и работает по крайней мере на 95 языках.

При этом она умеет писать длинные тексты, отвечать на вопросы и составлять практически любые материалы: бизнес-планы, рекламные стратегии, шутки, сценарии фильмов, приглашения на вечеринку и многое другое

В начале февраля 2023 года количество пользователей чат-бота на основе языковой модели с генеративным искусственным интеллектом (ChatGPT) достигло 100 млн человек.

Большие языковые модели в сочетании с чат-ботами стали проникать в различные отрасли экономики и сферы общественных отношений. Эти технологические решения приобрели общий ("сквозной") характер. Они позволили по-другому взглянуть на результативность деятельности организаций и человека, подойти к проблеме обработки больших объемов данных, создаваемых как человеком, так и техническими устройствами.

Вместе с этим появился ряд вопросов о когнитивных способностях человека, не отупеет ли он, как будет развиваться и накапливать знания и экспертизу.

Исследованию этих вопросов и посвящена эта работа.
